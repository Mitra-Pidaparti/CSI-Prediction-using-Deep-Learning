{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10cEpOj61-ibKVbelj0z_4VS7-Yo0_mhm","authorship_tag":"ABX9TyO9shbNsbKPDvXv86Vrmti9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","import scipy.io as sio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","# Define the loss function\n","criterion = nn.MSELoss()\n","\n","# Define the compression ratios\n","compression_ratios = [4,8]\n","\n","def calculate_mse(outputs, targets):\n","    mse = criterion(outputs, targets)\n","    return mse\n","\n","def NMSE(outputs, inputs_resized):\n","    outputs_real = torch.reshape(outputs[:, 0, :, :], (outputs.size(0), -1))\n","    outputs_imag = torch.reshape(outputs[:, 1, :, :], (outputs.size(0), -1))\n","    outputs_comp = (outputs_real - 0.5) + 1j * (outputs_imag - 0.5)\n","\n","    inputs_resized_real = torch.reshape(inputs_resized[:, 0, :, :], (inputs_resized.size(0), -1))\n","    inputs_resized_imag = torch.reshape(inputs_resized[:, 1, :, :], (inputs_resized.size(0), -1))\n","    inputs_resized_comp = (inputs_resized_real - 0.5) + 1j * (inputs_resized_imag - 0.5)\n","\n","    mse = torch.mean(torch.abs(outputs_comp - inputs_resized_comp) ** 2, dim=1)\n","    power = torch.mean(torch.abs(inputs_resized_comp) ** 2, dim=1)\n","\n","    nmse = 10 * torch.log10(torch.mean(mse / power))\n","\n","    return nmse\n","\n","\n","import torch.nn as nn\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(self, compressed_dim, height, width):\n","        super(EncoderBlock, self).__init__()\n","        self.conv = nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1)  # Adjusted number of input channels to 4\n","        self.bn = nn.BatchNorm2d(2)\n","        self.relu = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","        self.dense = nn.Linear(2 * height * width, compressed_dim)\n","        self.height = height\n","        self.width = width\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.flatten(x)\n","        x = self.dense(x)\n","        return x\n","\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, compressed_dim, height, width):\n","        super(DecoderBlock, self).__init__()\n","        self.compressed_dim = compressed_dim\n","        self.height = height\n","        self.width = width\n","        self.dense = nn.Linear(compressed_dim, 2 * (height) * (width))\n","        self.conv1 = nn.Conv2d(2, 4, kernel_size=1, stride=1)\n","        self.bn1 = nn.BatchNorm2d(4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2_upper = nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1)\n","        self.bn2_upper = nn.BatchNorm2d(4)\n","        self.conv2_upper2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n","        self.bn2_upper2 = nn.BatchNorm2d(8)\n","        self.conv2_lower = nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1)\n","        self.bn2_lower = nn.BatchNorm2d(4)\n","        self.conv2_lower2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n","        self.bn2_lower2 = nn.BatchNorm2d(8)\n","        self.conv3 = nn.Conv2d(16, 4, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(4)\n","        self.conv4 = nn.Conv2d(4, 2, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm2d(2)\n","        self.reconstruction = nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1)\n","\n","    def forward(self, x):\n","        x = self.dense(x)\n","        x = x.view(-1, 2, self.height, self.width)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","\n","        upper_branch = self.conv2_upper(x)\n","        upper_branch = self.bn2_upper(upper_branch)\n","\n","        upper_branch = self.conv2_upper2(upper_branch)\n","        upper_branch = self.bn2_upper2(upper_branch)\n","\n","        lower_branch = self.conv2_lower(x)\n","        lower_branch = self.bn2_lower(lower_branch)\n","\n","        lower_branch = self.conv2_lower2(lower_branch)\n","        lower_branch = self.bn2_lower2(lower_branch)\n","\n","        x = torch.cat([upper_branch, lower_branch], dim=1)\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = self.reconstruction(x)\n","\n","        x_reshaped = x.view(-1, 2, self.height, self.width)\n","        x = x + x_reshaped\n","        return x\n","\n","\n","class LightweightCNN(nn.Module):\n","    def __init__(self, compressed_dim, height, width):\n","        super(LightweightCNN, self).__init__()\n","        self.encoder = EncoderBlock(compressed_dim, height, width)\n","        self.decoder = DecoderBlock(compressed_dim, height, width)\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n","\n","\n","# Load the data\n","train_data = torch.from_numpy(sio.loadmat(r\"C:\\Users\\mitra\\OneDrive\\Desktop\\Model4 dataset\\Model4 train dataset\\UMi_LOS_V_freq_subband_train.mat\")['x'])\n","test_data=torch.from_numpy(sio.loadmat(r\"C:\\Users\\mitra\\OneDrive\\Desktop\\Model4 dataset\\Model4 test dataset\\UMi_LOS_V_freq_subband_test.mat\")['x'])\n","train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Create a new folder to save model parameters\n","save_folder = r\"C:\\Users\\mitra\\OneDrive\\Desktop\\Lightweight model parameters for different CRs\\UMi_LOS_freq_subband\"\n","\n","for cr in compression_ratios:\n","    print(f\"Training, validating, and testing for compression ratio 1/{cr}\")\n","\n","    def plot_train_loss(train_loss_list):\n","        train_loss = train_loss_list\n","        plt.plot(range(1, num_epochs + 1),train_loss)\n","        plt.xlabel('Epoch')\n","        plt.ylabel('(Training Loss)')\n","        plt.title('Training Loss vs. Epoch')\n","        plt.show()\n","\n","    train_loss_list = []\n","\n","\n","\n","    # Normalize the datasets\n","    max_abs_train = torch.max(torch.abs(train_data))\n","    max_abs_test = torch.max(torch.abs(test_data))\n","    max_abs_val = torch.max(torch.abs(val_data))\n","\n","    train_data_normalized = train_data / max_abs_train * 0.5 + 0.5\n","    test_data_normalized = test_data / max_abs_test * 0.5 + 0.5\n","    val_data_normalized = val_data / max_abs_val * 0.5 + 0.5\n","\n","    # Define the dimensions\n","    compressed_dim = int(2 * 32 * 32 * (1 / cr))\n","    height = 32\n","    width = 32\n","    model = LightweightCNN(compressed_dim, height, width)\n","    # Define the optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Split the data into train and validation sets\n","    # train_data, val_data = train_test_split(train_data_normalized, test_size=0.2)\n","    compressed_train_data = train_data_normalized.view(-1, 2, 32, 32).to(torch.float32)\n","    compressed_val_data = val_data_normalized.view(-1, 2, 32, 32).to(torch.float32)\n","\n","    # Create DataLoaders for training and validation data\n","    train_loader = DataLoader(compressed_train_data, batch_size=100, shuffle=True)\n","    val_loader = DataLoader(compressed_val_data, batch_size=100)\n","\n","    # Train the model\n","    model.to(device)\n","    model.train()\n","\n","    num_epochs = 250  # Increase the number of epochs for better training\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        for inputs in train_loader:\n","            inputs = inputs.to(device)\n","\n","            # Zero the gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Resize the input tensor to match the output shape\n","            inputs_resized = inputs[:, :2, :, :]\n","\n","            # Compute the MSE loss\n","            loss = criterion(outputs, inputs_resized)\n","\n","            # Backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Update the running loss\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        # Calculate the average loss for training set\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_loss_list.append(train_loss)\n","\n","        # Validate the model\n","        model.eval()\n","        running_loss = 0.0\n","\n","        with torch.no_grad():\n","            for val_inputs in val_loader:\n","                val_inputs = val_inputs.to(device)\n","\n","                # Forward pass\n","                val_outputs = model(val_inputs)\n","\n","                # Resize the input tensor to match the output shape\n","                val_inputs_resized = val_inputs[:, :2, :, :]\n","\n","                # Compute the MSE loss\n","                val_loss = criterion(val_outputs, val_inputs_resized)\n","\n","                # Update the running loss\n","                running_loss += val_loss.item() * val_inputs.size(0)\n","\n","        # Calculate the average loss for validation set\n","        val_loss = running_loss / len(val_loader.dataset)\n","\n","        # Print the epoch and loss for training and validation sets\n","        print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss} - Val Loss: {val_loss}\")\n","    plot_train_loss(train_loss_list)\n","    # Compress the test data\n","    # compressed_test_data = test_data[:, :, ::cr, ::cr]\n","    compressed_test_data = test_data_normalized.view(-1, 2, 32, 32).to(torch.float32)\n","\n","    # Create DataLoader for test data\n","    test_loader = DataLoader(compressed_test_data, batch_size=100)\n","    # Convert the model's parameters to the same data type as the input data\n","    # model.to(inputs.dtype)\n","    # Test the model\n","    model.eval()\n","    running_loss = 0.0\n","    running_loss_mse = 0.0\n","\n","    with torch.no_grad():\n","        for inputs in test_loader:\n","            inputs = inputs.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Resize the input tensor to match the output shape\n","            inputs_resized = inputs[:, :2, :, :]\n","\n","            # Compute the MSE loss\n","            loss = NMSE(outputs, inputs_resized)\n","            loss_mse = criterion(outputs, inputs_resized)\n","\n","            # Update the running loss\n","            running_loss += loss.item() * inputs.size(0)\n","            running_loss_mse += loss_mse.item() * inputs.size(0)\n","\n","    # Calculate the average loss for test set\n","    test_loss = running_loss / len(test_loader.dataset)\n","    test_loss_mse = running_loss_mse / len(test_loader.dataset)\n","\n","    # Print the test loss\n","    print(f\"nmse: {test_loss}\")\n","    print(f\"Test Loss: {test_loss_mse}\")\n","\n","    # Save the model/weights\n","    save_path = os.path.join(save_folder, f\"CR_{cr}\")\n","    os.makedirs(save_path, exist_ok=True)\n","    torch.save(model.state_dict(), os.path.join(save_path, \"model_weights.pth\"))\n"],"metadata":{"id":"4ujd4FT02KKl"},"execution_count":null,"outputs":[]}]}